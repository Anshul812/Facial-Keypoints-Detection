{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models import Net\n",
    "\n",
    "net = gpu(Net())\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "\n",
    "from data_load import FacialKeypointsDataset\n",
    "\n",
    "from data_load import Rescale, RandomCrop, Normalize, ToTensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_transform = None\n",
    "\n",
    "\n",
    "assert(data_transform is not None), 'Define a data_transform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = FacialKeypointsDataset(csv_file='data\\\\training_frames_keypoints.csv',\n",
    "                                      root_dir='data\\\\training\\\\',\n",
    "                                             transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of images: ', len(transformed_dataset))\n",
    "\n",
    "# make sure the sample tensors are the expected size\n",
    "for i in range(5):\n",
    "    sample = transformed_dataset[i]\n",
    "    print(i, sample['image'].size(), sample['keypoints'].size())\n",
    "    \n",
    "transformed_dataset[1]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(transformed_dataset, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True, \n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the test dataset\n",
    "test_dataset = FacialKeypointsDataset(csv_file='data\\\\test_frames_keypoints.csv',\n",
    "                                      root_dir='data\\\\test\\\\',\n",
    "                                             transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data in batches\n",
    "batch_size = 128\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True, \n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model on a batch of test images\n",
    "\n",
    "def net_sample_output():\n",
    "    \n",
    "    # iterate through the test dataset\n",
    "    for i, sample in enumerate(test_loader):\n",
    "        \n",
    "        # get sample data: images and ground truth keypoints\n",
    "        images = sample['image']\n",
    "        key_pts = sample['keypoints']\n",
    "\n",
    "        # convert images to FloatTensors\n",
    "        images = images.type(torch.cuda.FloatTensor)\n",
    "\n",
    "        # forward pass to get net output\n",
    "        output_pts = net(images)\n",
    "        \n",
    "        # reshape to batch_size x 68 x 2 pts\n",
    "        output_pts = output_pts.view(output_pts.size()[0], 68, -1)\n",
    "        \n",
    "        # break after first image is tested\n",
    "        if i == 0:\n",
    "            return images, output_pts, key_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_outputs, gt_pts = net_sample_output()\n",
    "\n",
    "# print out the dimensions of the data to see if they make sense\n",
    "print(test_images.data.size())\n",
    "print(test_outputs.data.size())\n",
    "print(gt_pts.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all_keypoints(image, predicted_key_pts, gt_pts=None):\n",
    "    \"\"\"Show image with predicted keypoints\"\"\"\n",
    "    # image is grayscale\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.scatter(predicted_key_pts[:, 0], predicted_key_pts[:, 1], s=20, marker='.', c='r')\n",
    "    # plot ground truth points as green pts\n",
    "    if gt_pts is not None:\n",
    "        plt.scatter(gt_pts[:, 0], gt_pts[:, 1], s=20, marker='.', c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_output(test_images, test_outputs, gt_pts=None, batch_size=10):\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        plt.figure(figsize=(20,10))\n",
    "        ax = plt.subplot(1, batch_size, i+1)\n",
    "\n",
    "       \n",
    "        image = test_images[i].data   \n",
    "        image = image.cpu().numpy()   # convert to numpy array from a Tensor\n",
    "        image = np.transpose(image, (1, 2, 0))   # transpose to go from torch to numpy image\n",
    "\n",
    "        \n",
    "        predicted_key_pts = test_outputs[i].data\n",
    "        predicted_key_pts = predicted_key_pts.cpu().numpy()\n",
    "        \n",
    "        predicted_key_pts = predicted_key_pts*50.0+100\n",
    "        \n",
    "        # plot ground truth points for comparison, if they exist\n",
    "        ground_truth_pts = None\n",
    "        if gt_pts is not None:\n",
    "            ground_truth_pts = gt_pts[i]         \n",
    "            ground_truth_pts = ground_truth_pts*50.0+100\n",
    "        \n",
    "        # call show_all_keypoints\n",
    "        show_all_keypoints(np.squeeze(image), predicted_key_pts, ground_truth_pts)\n",
    "            \n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# call it\n",
    "visualize_output(test_images, test_outputs, gt_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = gpu(nn.MSELoss())\n",
    "\n",
    "# ADAM optimizer\n",
    "initial_lr=0.0001\n",
    "optimizer = optim.Adam(net.parameters(), lr=initial_lr, amsgrad=True, weight_decay=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqrt_lr_scheduler(optimizer, epoch, init_lr=initial_lr, steps=50):\n",
    "    \"\"\"Decay learning rate by the square root of the epoch.\"\"\"\n",
    "    if (epoch % steps) == 0:\n",
    "        lr = init_lr / np.sqrt(epoch+1)\n",
    "        print(f'Adjusted learning rate: {lr:.6f}')\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(n_epochs, initial_lr=initial_lr):\n",
    "    global optimizer\n",
    "    # prepare the net for training\n",
    "    net.train()\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        #optimizer = sqrt_lr_scheduler(optimizer, epoch, initial_lr)\n",
    "\n",
    "        # train on batches of data, assumes you already have train_loader\n",
    "        for batch_i, data in enumerate(train_loader):\n",
    "            # get the input images and their corresponding labels\n",
    "            images = data['image']\n",
    "            key_pts = data['keypoints']\n",
    "\n",
    "            # flatten pts\n",
    "            key_pts = key_pts.view(key_pts.size(0), -1)\n",
    "            \n",
    "            # wrap them in a torch Variable\n",
    "\n",
    "            # convert variables to floats for regression loss\n",
    "            key_pts = gpu(key_pts.type(torch.FloatTensor))\n",
    "            images = gpu(images.type(torch.FloatTensor))\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            output_pts = net(images)\n",
    "\n",
    "            # calculate the loss between predicted and target keypoints\n",
    "            loss = criterion(output_pts, key_pts)\n",
    "\n",
    "            # zero the parameter (weight) gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # backward pass to calculate the weight gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # print loss statistics\n",
    "            running_loss += loss.data[0]\n",
    "            if batch_i % 20 == 19:    # print every 20 batches\n",
    "                print('Epoch: {}, Batch: {}, Avg. Loss: {}'.format(epoch + 1, batch_i+1, running_loss/1000))\n",
    "                running_loss = 0.0\n",
    "        losses.append(running_loss)\n",
    "\n",
    "    print('Finished Training')\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train your network\n",
    "n_epochs = 1100 \n",
    "\n",
    "losses = train_net(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = train_net(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(losses)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample of test data again\n",
    "test_images, test_outputs, gt_pts = net_sample_output()\n",
    "\n",
    "print(test_images.data.size())\n",
    "print(test_outputs.data.size())\n",
    "print(gt_pts.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_output(test_images, test_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dir = ''\n",
    "model_name = 'keypoints_model_1.pt'\n",
    "\n",
    "# after training, save your model parameters in the dir 'saved_models'\n",
    "torch.save(net.state_dict(), model_dir+model_name)\n",
    "#torch.save(net, model_dir+model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
